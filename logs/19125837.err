Loaded module: cuda/11.6
Loaded dependency [python3/3.11.4]: gcc/12.3.0-binutils-2.40
Loaded dependency [python3/3.11.4]: sqlite3/3.42.0
Loaded module: python3/3.11.4

Loading python3/3.11.4
  Loading requirement: gcc/12.3.0-binutils-2.40 sqlite3/3.42.0
Found cached dataset parquet (/work3/s212722/herd/datasets/cache/alexrs___parquet/alexrs--alpaca-cleaned-30-clusters-a73d614e768ecc90/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)
2023-11-02 09:23:30.134 | INFO     | herd.finetune_utils:get_peft_config:30 - Fine-tuning with MoLoRA using 30 experts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.38s/it]
2023-11-02 09:24:18.338 | INFO     | herd.finetune:_finetune_router:149 - Loading experts: dict_keys(['expert_0', 'expert_1', 'expert_2', 'expert_3', 'expert_4', 'expert_5', 'expert_6', 'expert_7', 'expert_8', 'expert_9', 'expert_10', 'expert_11', 'expert_12', 'expert_13', 'expert_14', 'expert_15', 'expert_16', 'expert_17', 'expert_18', 'expert_19', 'expert_20', 'expert_21', 'expert_22', 'expert_23', 'expert_24', 'expert_25', 'expert_26', 'expert_27', 'expert_28', 'expert_29'])
Traceback (most recent call last):
  File "/zhome/03/c/164482/code/herd/main.py", line 68, in <module>
    main()
  File "/zhome/03/c/164482/code/herd/main.py", line 54, in main
    finetune(model_values, path_values, config, experts, args.peft_strategy, args.is_base, args.use_base, args.only_router, args.all, args.top_k)
  File "/zhome/03/c/164482/code/herd/herd/finetune.py", line 227, in finetune
    _finetune_router(dataset, tokenizer, config, experts, peft_strategy, model_values, path_values, top_k)
  File "/zhome/03/c/164482/code/herd/herd/finetune.py", line 151, in _finetune_router
    model_peft.load_experts(output_dir, 'default', list(experts.keys()), True)
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/peft/peft_model.py", line 661, in load_experts
    expert_weights.append(load_peft_weights(os.path.join(model_id, expert), device=torch_device, **hf_hub_download_kwargs))
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py", line 194, in load_peft_weights
    has_remote_safetensors_file = hub_file_exists(
                                  ^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/peft/utils/hub_utils.py", line 24, in hub_file_exists
    url = hf_hub_url(repo_id=repo_id, filename=filename, repo_type=repo_type, revision=revision)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/work3/s212722/herd/meta-llama/Llama-2-7b-hf/alpaca-30/all_linear_paged_adam_4bit/molora/expert_8'. Use `repo_type` argument if needed.
