Loaded module: cuda/11.6
Loaded dependency [python3/3.11.4]: gcc/12.3.0-binutils-2.40
Loaded dependency [python3/3.11.4]: sqlite3/3.42.0
Loaded module: python3/3.11.4

Loading python3/3.11.4
  Loading requirement: gcc/12.3.0-binutils-2.40 sqlite3/3.42.0
Found cached dataset parquet (/work3/s212722/herd/datasets/cache/alexrs___parquet/alexrs--alpaca-cleaned-10-clusters-e0d2361138237477/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)
Loading cached processed dataset at /work3/s212722/herd/datasets/cache/alexrs___parquet/alexrs--alpaca-cleaned-10-clusters-e0d2361138237477/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-dd77dbeeee1b1a95.arrow
2023-11-05 10:55:17.967 | INFO     | herd.finetune_utils:get_peft_config:30 - Fine-tuning with MoLoRA using 10 experts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:09<04:09, 249.31s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:45<04:45, 285.99s/it]
Traceback (most recent call last):
  File "/zhome/03/c/164482/code/herd/main.py", line 78, in <module>
    main()
  File "/zhome/03/c/164482/code/herd/main.py", line 55, in main
    finetune(
  File "/zhome/03/c/164482/code/herd/herd/finetune.py", line 266, in finetune
    _finetune_experts(dataset, tokenizer, config, experts, peft_strategy, use_base, model_values, path_values)
  File "/zhome/03/c/164482/code/herd/herd/finetune.py", line 196, in _finetune_experts
    model, peft_config = prepare_model(model_values.model, path_values.cache_dir, config, peft_strategy)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/herd/finetune_utils.py", line 39, in prepare_model
    model = AutoModelForCausalLM.from_pretrained(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 565, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 3307, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 3695, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 749, in _load_state_dict_into_meta_model
    set_module_quantized_tensor_to_device(
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/transformers/integrations/bitsandbytes.py", line 98, in set_module_quantized_tensor_to_device
    new_value = bnb.nn.Params4bit(new_value, requires_grad=False, **kwargs).to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/bitsandbytes/nn/modules.py", line 179, in to
    return self.cuda(device)
           ^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/bitsandbytes/nn/modules.py", line 156, in cuda
    w = self.data.contiguous().half().cuda(device)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
