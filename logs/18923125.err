Loaded module: cuda/11.6
Loaded dependency [python3/3.11.4]: gcc/12.3.0-binutils-2.40
Loaded dependency [python3/3.11.4]: sqlite3/3.42.0
Loaded module: python3/3.11.4

Loading python3/3.11.4
  Loading requirement: gcc/12.3.0-binutils-2.40 sqlite3/3.42.0
Found cached dataset parquet (/work3/s212722/herd/datasets/cache/alexrs___parquet/alexrs--alpaca-cleaned-30-clusters-a73d614e768ecc90/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)
Filter:   0%|          | 0/51760 [00:00<?, ? examples/s]Filter:   6%|▌         | 3000/51760 [00:00<00:01, 25535.94 examples/s]Filter:  15%|█▌        | 8000/51760 [00:00<00:01, 34585.28 examples/s]Filter:  25%|██▌       | 13000/51760 [00:00<00:01, 36990.18 examples/s]Filter:  33%|███▎      | 17000/51760 [00:00<00:00, 37246.70 examples/s]Filter:  43%|████▎     | 22000/51760 [00:00<00:00, 37804.36 examples/s]Filter:  52%|█████▏    | 27000/51760 [00:00<00:00, 37967.98 examples/s]Filter:  60%|█████▉    | 31000/51760 [00:00<00:00, 37588.69 examples/s]Filter:  68%|██████▊   | 35000/51760 [00:00<00:00, 37188.90 examples/s]Filter:  75%|███████▌  | 39000/51760 [00:01<00:00, 37338.93 examples/s]Filter:  85%|████████▌ | 44000/51760 [00:01<00:00, 37979.58 examples/s]Filter:  95%|█████████▍| 49000/51760 [00:01<00:00, 37969.80 examples/s]                                                                       2023-10-28 16:30:29.252 | INFO     | herd.finetune_utils:get_peft_config:30 - Fine-tuning with MoLoRA using 30 experts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-10-28 16:30:37.915 | WARNING  | herd.finetune:_finetune_experts:174 - Number of experts is not 1 but we are training an expert, setting it to 1. num_experts: 1
Traceback (most recent call last):
  File "/zhome/03/c/164482/code/herd/main.py", line 68, in <module>
    main()
  File "/zhome/03/c/164482/code/herd/main.py", line 54, in main
    finetune(model_values, path_values, config, experts, args.peft_strategy, args.is_base, args.use_base, args.only_router, args.all, args.top_k)
  File "/zhome/03/c/164482/code/herd/herd/finetune.py", line 222, in finetune
    _finetune_experts(dataset, tokenizer, config, experts, peft_strategy, use_base, model_values, path_values)
  File "/zhome/03/c/164482/code/herd/herd/finetune.py", line 177, in _finetune_experts
    model.load_adapter(base_path, "default")
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/peft/peft_model.py", line 593, in load_adapter
    adapters_weights = load_peft_weights(model_id, device=torch_device, **hf_hub_download_kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py", line 194, in load_peft_weights
    has_remote_safetensors_file = hub_file_exists(
                                  ^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/peft/utils/hub_utils.py", line 24, in hub_file_exists
    url = hf_hub_url(repo_id=repo_id, filename=filename, repo_type=repo_type, revision=revision)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/work3/s212722/herd/meta-llama/Llama-2-7b-hf/alpaca-30/all_linear_paged_adam_4bit/molora/base'. Use `repo_type` argument if needed.
