Loaded module: cuda/11.6
Loaded dependency [python3/3.11.4]: gcc/12.3.0-binutils-2.40
Loaded dependency [python3/3.11.4]: sqlite3/3.42.0
Loaded module: python3/3.11.4

Loading python3/3.11.4
  Loading requirement: gcc/12.3.0-binutils-2.40 sqlite3/3.42.0
Found cached dataset parquet (/work3/s212722/herd/datasets/cache/alexrs___parquet/alexrs--alpaca-cleaned-10-clusters-e0d2361138237477/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)
Loading cached processed dataset at /work3/s212722/herd/datasets/cache/alexrs___parquet/alexrs--alpaca-cleaned-10-clusters-e0d2361138237477/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-9cb23e54d08fb3ef.arrow
2023-11-05 17:07:56.373 | INFO     | herd.finetune_utils:get_peft_config:30 - Fine-tuning with MoLoRA using 10 experts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:05<04:05, 245.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [05:34<00:00, 153.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [05:34<00:00, 167.16s/it]
2023-11-05 17:13:33.567 | WARNING  | herd.finetune:_finetune_experts:203 - Number of experts is not 1 but we are training an expert, setting it to 1. num_experts: 1
/zhome/03/c/164482/code/herd/.venv/lib/python3.11/site-packages/trl/trainer/utils.py:246: UserWarning: The passed formatting_func has more than one argument. Usually that function should have a single argument `example` which corresponds to the dictonnary returned by each element of the dataset. Make sure you know what you are doing.
  warnings.warn(
2023-11-05 17:13:42.290 | INFO     | herd.finetune:_finetune_experts:235 - Training expert: expert_8, output_dir: /work3/s212722/herd/meta-llama/Llama-2-7b-hf/alpaca-10/q_v_r4/molora/expert_8
wandb: Currently logged in as: alexrs95. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /zhome/03/c/164482/code/herd/wandb/run-20231105_171344-z8xc1hpq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run molora/expert_8
wandb: ⭐️ View project at https://wandb.ai/alexrs95/herd-llama
wandb: 🚀 View run at https://wandb.ai/alexrs95/herd-llama/runs/z8xc1hpq
  0%|          | 0/1498 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/1498 [00:12<5:08:15, 12.36s/it]  0%|          | 2/1498 [00:21<4:26:55, 10.71s/it]  0%|          | 3/1498 [00:31<4:13:34, 10.18s/it]  0%|          | 4/1498 [00:41<4:07:20,  9.93s/it]  0%|          | 5/1498 [00:50<4:03:51,  9.80s/it]  0%|          | 6/1498 [01:00<4:01:47,  9.72s/it]  0%|          | 7/1498 [01:09<4:00:30,  9.68s/it]  1%|          | 8/1498 [01:19<3:59:37,  9.65s/it]  1%|          | 9/1498 [01:28<3:59:07,  9.64s/it]  1%|          | 10/1498 [01:38<3:58:39,  9.62s/it]                                                     1%|          | 10/1498 [01:38<3:58:39,  9.62s/it]  1%|          | 11/1498 [01:48<3:58:24,  9.62s/it]  1%|          | 12/1498 [01:57<3:58:11,  9.62s/it]  1%|          | 13/1498 [02:07<3:58:03,  9.62s/it]  1%|          | 14/1498 [02:16<3:57:54,  9.62s/it]  1%|          | 15/1498 [02:26<3:57:46,  9.62s/it]  1%|          | 16/1498 [02:36<3:57:38,  9.62s/it]  1%|          | 17/1498 [02:45<3:57:29,  9.62s/it]  1%|          | 18/1498 [02:55<3:57:18,  9.62s/it]  1%|▏         | 19/1498 [03:05<3:57:12,  9.62s/it]  1%|▏         | 20/1498 [03:14<3:57:05,  9.62s/it]                                                     1%|▏         | 20/1498 [03:14<3:57:05,  9.62s/it]  1%|▏         | 21/1498 [03:24<3:56:49,  9.62s/it]  1%|▏         | 22/1498 [03:33<3:56:42,  9.62s/it]  2%|▏         | 23/1498 [03:43<3:56:36,  9.62s/it]  2%|▏         | 24/1498 [03:53<3:56:24,  9.62s/it]  2%|▏         | 25/1498 [04:02<3:56:18,  9.63s/it]  2%|▏         | 26/1498 [04:12<3:56:07,  9.62s/it]  2%|▏         | 27/1498 [04:22<3:56:00,  9.63s/it]  2%|▏         | 28/1498 [04:31<3:55:39,  9.62s/it]  2%|▏         | 29/1498 [04:41<3:55:29,  9.62s/it]  2%|▏         | 30/1498 [04:50<3:55:23,  9.62s/it]                                                     2%|▏         | 30/1498 [04:50<3:55:23,  9.62s/it]  2%|▏         | 31/1498 [05:00<3:55:16,  9.62s/it]  2%|▏         | 32/1498 [05:10<3:55:06,  9.62s/it]  2%|▏         | 33/1498 [05:19<3:54:57,  9.62s/it]  2%|▏         | 34/1498 [05:29<3:54:47,  9.62s/it]  2%|▏         | 35/1498 [05:39<3:54:43,  9.63s/it]  2%|▏         | 36/1498 [05:48<3:54:26,  9.62s/it]  2%|▏         | 37/1498 [05:58<3:54:15,  9.62s/it]  3%|▎         | 38/1498 [06:07<3:54:08,  9.62s/it]  3%|▎         | 39/1498 [06:17<3:54:03,  9.63s/it]  3%|▎         | 40/1498 [06:27<3:53:55,  9.63s/it]                                                     3%|▎         | 40/1498 [06:27<3:53:55,  9.63s/it]  3%|▎         | 41/1498 [06:36<3:53:42,  9.62s/it]  3%|▎         | 42/1498 [06:46<3:53:22,  9.62s/it]  3%|▎         | 43/1498 [06:56<3:53:11,  9.62s/it]  3%|▎         | 44/1498 [07:05<3:53:07,  9.62s/it]  3%|▎         | 45/1498 [07:15<3:53:01,  9.62s/it]  3%|▎         | 46/1498 [07:24<3:52:54,  9.62s/it]  3%|▎         | 47/1498 [07:34<3:52:44,  9.62s/it]  3%|▎         | 48/1498 [07:44<3:52:35,  9.62s/it]  3%|▎         | 49/1498 [07:53<3:52:26,  9.62s/it]  3%|▎         | 50/1498 [08:03<3:52:17,  9.63s/it]                                                     3%|▎         | 50/1498 [08:03<3:52:17,  9.63s/it]  3%|▎         | 51/1498 [08:13<3:52:10,  9.63s/it]  3%|▎         | 52/1498 [08:22<3:52:00,  9.63s/it]  4%|▎         | 53/1498 [08:32<3:51:52,  9.63s/it]  4%|▎         | 54/1498 [08:41<3:51:42,  9.63s/it]  4%|▎         | 55/1498 [08:51<3:51:29,  9.63s/it]  4%|▎         | 56/1498 [09:01<3:51:21,  9.63s/it]  4%|▍         | 57/1498 [09:10<3:51:05,  9.62s/it]  4%|▍         | 58/1498 [09:20<3:50:59,  9.62s/it]  4%|▍         | 59/1498 [09:30<3:50:51,  9.63s/it]  4%|▍         | 60/1498 [09:39<3:50:44,  9.63s/it]                                                     4%|▍         | 60/1498 [09:39<3:50:44,  9.63s/it]  4%|▍         | 61/1498 [09:49<3:50:35,  9.63s/it]  4%|▍         | 62/1498 [09:58<3:50:25,  9.63s/it]  4%|▍         | 63/1498 [10:08<3:50:18,  9.63s/it]  4%|▍         | 64/1498 [10:18<3:50:04,  9.63s/it]  4%|▍         | 65/1498 [10:27<3:49:54,  9.63s/it]  4%|▍         | 66/1498 [10:37<3:49:46,  9.63s/it]  4%|▍         | 67/1498 [10:44<3:33:53,  8.97s/it]  5%|▍         | 68/1498 [10:55<3:46:27,  9.50s/it]  5%|▍         | 69/1498 [11:05<3:47:08,  9.54s/it]  5%|▍         | 70/1498 [11:14<3:47:33,  9.56s/it]                                                     5%|▍         | 70/1498 [11:14<3:47:33,  9.56s/it]  5%|▍         | 71/1498 [11:24<3:47:51,  9.58s/it]  5%|▍         | 72/1498 [11:34<3:48:00,  9.59s/it]  5%|▍         | 73/1498 [11:43<3:48:02,  9.60s/it]  5%|▍         | 74/1498 [11:53<3:48:00,  9.61s/it]  5%|▌         | 75/1498 [12:02<3:47:57,  9.61s/it]  5%|▌         | 76/1498 [12:12<3:47:56,  9.62s/it]  5%|▌         | 77/1498 [12:22<3:47:50,  9.62s/it]  5%|▌         | 78/1498 [12:31<3:47:37,  9.62s/it]  5%|▌         | 79/1498 [12:41<3:47:27,  9.62s/it]  5%|▌         | 80/1498 [12:51<3:47:23,  9.62s/it]                                                     5%|▌         | 80/1498 [12:51<3:47:23,  9.62s/it]  5%|▌         | 81/1498 [13:00<3:47:14,  9.62s/it]  5%|▌         | 82/1498 [13:10<3:47:07,  9.62s/it]  6%|▌         | 83/1498 [13:19<3:46:55,  9.62s/it]  6%|▌         | 84/1498 [13:29<3:46:44,  9.62s/it]  6%|▌         | 85/1498 [13:39<3:46:34,  9.62s/it]  6%|▌         | 86/1498 [13:48<3:46:27,  9.62s/it]  6%|▌         | 87/1498 [13:58<3:46:17,  9.62s/it]  6%|▌         | 88/1498 [14:08<3:46:09,  9.62s/it]  6%|▌         | 89/1498 [14:17<3:45:58,  9.62s/it]  6%|▌         | 90/1498 [14:27<3:45:45,  9.62s/it]                                                     6%|▌         | 90/1498 [14:27<3:45:45,  9.62s/it]  6%|▌         | 91/1498 [14:36<3:45:34,  9.62s/it]  6%|▌         | 92/1498 [14:46<3:45:32,  9.62s/it]  6%|▌         | 93/1498 [14:56<3:45:24,  9.63s/it]  6%|▋         | 94/1498 [15:05<3:45:14,  9.63s/it]  6%|▋         | 95/1498 [15:15<3:45:05,  9.63s/it]  6%|▋         | 96/1498 [15:25<3:44:55,  9.63s/it]  6%|▋         | 97/1498 [15:34<3:44:44,  9.62s/it]  7%|▋         | 98/1498 [15:44<3:44:32,  9.62s/it]  7%|▋         | 99/1498 [15:53<3:44:26,  9.63s/it]  7%|▋         | 100/1498 [16:03<3:44:17,  9.63s/it]                                                      7%|▋         | 100/1498 [16:03<3:44:17,  9.63s/it]  7%|▋         | 101/1498 [16:13<3:44:09,  9.63s/it]  7%|▋         | 102/1498 [16:22<3:43:59,  9.63s/it]  7%|▋         | 103/1498 [16:32<3:43:48,  9.63s/it]  7%|▋         | 104/1498 [16:42<3:43:36,  9.62s/it]  7%|▋         | 105/1498 [16:51<3:43:27,  9.63s/it]  7%|▋         | 106/1498 [17:01<3:43:11,  9.62s/it]  7%|▋         | 107/1498 [17:10<3:43:01,  9.62s/it]  7%|▋         | 108/1498 [17:20<3:42:55,  9.62s/it]  7%|▋         | 109/1498 [17:30<3:42:48,  9.62s/it]  7%|▋         | 110/1498 [17:39<3:42:40,  9.63s/it]                                                      7%|▋         | 110/1498 [17:39<3:42:40,  9.63s/it]  7%|▋         | 111/1498 [17:49<3:42:28,  9.62s/it]  7%|▋         | 112/1498 [17:59<3:42:14,  9.62s/it]  8%|▊         | 113/1498 [18:08<3:42:02,  9.62s/it]  8%|▊         | 114/1498 [18:18<3:41:56,  9.62s/it]  8%|▊         | 115/1498 [18:27<3:41:48,  9.62s/it]  8%|▊         | 116/1498 [18:37<3:41:37,  9.62s/it]  8%|▊         | 117/1498 [18:47<3:41:30,  9.62s/it]  8%|▊         | 118/1498 [18:56<3:41:18,  9.62s/it]  8%|▊         | 119/1498 [19:06<3:41:06,  9.62s/it]  8%|▊         | 120/1498 [19:16<3:41:02,  9.62s/it]                                                      8%|▊         | 120/1498 [19:16<3:41:02,  9.62s/it]  8%|▊         | 121/1498 [19:25<3:40:54,  9.63s/it]  8%|▊         | 122/1498 [19:35<3:40:47,  9.63s/it]  8%|▊         | 123/1498 [19:44<3:40:36,  9.63s/it]  8%|▊         | 124/1498 [19:54<3:40:26,  9.63s/it]  8%|▊         | 125/1498 [20:04<3:40:10,  9.62s/it]  8%|▊         | 126/1498 [20:13<3:40:04,  9.62s/it]  8%|▊         | 127/1498 [20:23<3:39:57,  9.63s/it]  9%|▊         | 128/1498 [20:33<3:39:49,  9.63s/it]  9%|▊         | 129/1498 [20:42<3:39:40,  9.63s/it]  9%|▊         | 130/1498 [20:52<3:39:31,  9.63s/it]                                                      9%|▊         | 130/1498 [20:52<3:39:31,  9.63s/it]  9%|▊         | 131/1498 [21:01<3:39:19,  9.63s/it]  9%|▉         | 132/1498 [21:11<3:39:04,  9.62s/it]  9%|▉         | 133/1498 [21:21<3:38:58,  9.63s/it]  9%|▉         | 134/1498 [21:28<3:23:50,  8.97s/it]                                                      9%|▉         | 134/1498 [21:28<3:23:50,  8.97s/it]  9%|▉         | 134/1498 [21:28<3:38:38,  9.62s/it]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                    train/epoch ▁▁▁▁▁▁▇███████
wandb:              train/global_step ▁▂▂▃▃▄▄▅▆▆▇▇██
wandb:            train/learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                     train/loss █▄▄▄▄▃▃▁▂▁▂▁▂
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                    train/epoch 1.09
wandb:              train/global_step 134
wandb:            train/learning_rate 0.0003
wandb:                     train/loss 0.7545
wandb:               train/total_flos 8.674299222058598e+16
wandb:               train/train_loss 0.7908
wandb:            train/train_runtime 1291.4576
wandb: train/train_samples_per_second 9.276
wandb:   train/train_steps_per_second 1.16
wandb: 
wandb: 🚀 View run molora/expert_8 at: https://wandb.ai/alexrs95/herd-llama/runs/z8xc1hpq
wandb: ️⚡ View job at https://wandb.ai/alexrs95/herd-llama/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk5NjEyNzE2/version_details/v15
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231105_171344-z8xc1hpq/logs
